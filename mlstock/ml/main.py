import logging
import math
import time

import pandas as pd
from sklearn import linear_model

from mlstock.data import data_filter, data_loader
from mlstock.data.datasource import DataSource
from mlstock.factors.KDJ import KDJ
from mlstock.factors.MACD import MACD
from mlstock.utils import utils
from sklearn.preprocessing import StandardScaler

logger = logging.getLogger(__name__)

FACTORS = [MACD, KDJ]


def main(start_date, end_date, num):
    start_time = time.time()
    datasource = DataSource()
    df_stocks = data_filter.filter_stocks()
    df_stocks = df_stocks[:num]
    df_stocks_data = data_loader.weekly(datasource, df_stocks.ts_code, start_date, end_date)
    df_stocks = df_stocks.merge(df_stocks_data, on=['ts_code'], how="left")
    logger.debug("åŠ è½½[%d]åªè‚¡ç¥¨ %s~%s çš„æ•°æ® %d è¡Œï¼Œè€—æ—¶%.0fç§’", len(df_stocks), start_date, end_date, len(df_stocks),
                 time.time() - start_time)

    for factor_class in FACTORS:
        factor = factor_class(datasource)
        seris_factor = factor.calculate(df_stocks)
        df_stocks[factor.name] = seris_factor

    # åˆå¹¶æ²ªæ·±300çš„å‘¨æ”¶ç›Šç‡
    df_hs300 = datasource.index_weekly("000300.SH", start_date, end_date)
    df_hs300 = df_hs300[['trade_date', 'pct_chg']]
    df_hs300 = df_hs300.rename(columns={'pct_chg': 'pct_chg_hs300'})
    logger.debug("ä¸‹è½½æ²ªæ·±300 %s~%s æ•°æ® %d æ¡", start_date, end_date, len(df_hs300))
    df_stocks = df_stocks.merge(df_hs300, on=['trade_date'], how='left')
    logger.debug("åˆå¹¶æ²ªæ·±300 %d=>%d", len(df_stocks), len(df_stocks))

    # è®¡ç®—å‡ºå’ŒåŸºå‡†ï¼ˆæ²ªæ·±300ï¼‰çš„è¶…é¢æ”¶ç›Šç‡ï¼Œå¹¶ä¸”åŸºäºå®ƒï¼Œè®¾ç½®é¢„æµ‹æ ‡ç­¾'target'ï¼ˆé¢„æµ‹ä¸‹ä¸€æœŸï¼Œæ‰€ä»¥åšshiftï¼‰
    df_stocks['rm_rf'] = df_stocks.pct_chg - df_stocks.pct_chg_hs300
    df_stocks['target'] = df_stocks.groupby('ts_code').rm_rf.shift(-1)

    # æŒ‰ç…§0.8:0.2å’Œæ—¶é—´é¡ºåºï¼Œåˆ’åˆ†trainå’Œtest
    trade_dates = df_stocks.trade_date.sort_values().unique()
    div_num = math.ceil(len(trade_dates) * 0.8)
    train_dates = trade_dates[:div_num]
    test_dates = trade_dates[div_num:]
    df_train = df_stocks[df_stocks.trade_date.apply(lambda x: x in train_dates)]
    df_test = df_stocks[df_stocks.trade_date.apply(lambda x: x in test_dates)]

    # æŸåªè‚¡ç¥¨ä¸Šå¸‚12å‘¨å†…çš„æ•°æ®æ‰”æ‰ï¼Œä¸éœ€è¦
    a = pd.to_datetime(df_train.trade_date, format='%Y%m%d')
    b = pd.to_datetime(df_train.list_date, format='%Y%m%d')
    df_train = df_train[a - b > pd.Timedelta(12, unit='w')]
    a = pd.to_datetime(df_test.trade_date, format='%Y%m%d')
    b = pd.to_datetime(df_test.list_date, format='%Y%m%d')
    df_test = df_test[a - b > pd.Timedelta(12, unit='w')]

    """
    æ¯ä¸€åˆ—ï¼Œéƒ½å»æå€¼ï¼ˆTODOï¼šæ˜¯ä¸æ˜¯æŒ‰ç…§å„è‚¡è‡ªå·±çš„å€¼æ¥åšæ˜¯ä¸æ˜¯æ›´å¥½ï¼Ÿç°åœ¨æ˜¯æ‰€æœ‰çš„è‚¡ç¥¨ï¼‰
    ä¸­ä½æ•°å»æå€¼:
    - è®¾ç¬¬ T æœŸæŸå› å­åœ¨æ‰€æœ‰ä¸ªè‚¡ä¸Šçš„æš´éœ²åº¦åºåˆ—ä¸ºğ·ğ‘–
    - ğ·ğ‘€ä¸ºè¯¥åºåˆ—ä¸­ä½æ•°
    - ğ·ğ‘€1ä¸ºåºåˆ—|ğ·ğ‘– âˆ’ ğ·ğ‘€|çš„ä¸­ä½æ•°
    - åˆ™å°†åºåˆ—ğ·ğ‘–ä¸­æ‰€æœ‰å¤§äºğ·ğ‘€ + 5ğ·ğ‘€1çš„æ•°é‡è®¾ä¸ºğ·ğ‘€ + 5ğ·ğ‘€1
    - å°†åºåˆ—ğ·ğ‘–ä¸­æ‰€æœ‰å°äºğ·ğ‘€ âˆ’ 5ğ·ğ‘€1çš„æ•°é‡è®¾ä¸ºğ·ğ‘€ âˆ’ 5ğ·ğ‘€1
    """
    # ä¿ç•™feature
    feature_names = ['MACD', 'KDJ']
    df_features = df_train[feature_names]
    # æ¯åˆ—éƒ½æ±‚ä¸­ä½æ•°ï¼Œå’Œä¸­ä½æ•°ä¹‹å·®çš„ç»å¯¹å€¼çš„ä¸­ä½æ•°
    df_median = df_features.median()
    df_scope = df_features.apply(lambda x: x - df_median[x.name]).abs().median()

    def scaller(x):
        _max = df_median[x.name] + 5 * df_scope[x.name]
        _min = df_median[x.name] - 5 * df_scope[x.name]
        x = x.apply(lambda v: _min if v < _min else v)
        x = x.apply(lambda v: _max if v > _max else v)
        return x

    df_features = df_features.apply(scaller)
    df_train[feature_names] = df_features

    # æ ‡å‡†åŒ–
    scaler = StandardScaler()
    scaler.fit(df_train[feature_names])
    df_train[feature_names] = scaler.transform(df_train[feature_names])
    df_test[feature_names] = scaler.transform(df_test[feature_names])

    # å»é™¤æ‰€æœ‰çš„NANæ•°æ®
    df_train.dropna(subset=feature_names+['target'], inplace=True)
    df_test.dropna(subset=feature_names+['target'], inplace=True)
    logger.debug("NAç»Ÿè®¡ï¼štrain dataï¼š%r,labelï¼š%r",
                 df_train[feature_names].isna().sum(),
                 df_test[feature_names].isna().sum())

    # å‡†å¤‡è®­ç»ƒç”¨æ•°æ®ï¼Œéœ€è¦numpyç±»å‹
    X_train = df_train[feature_names].values
    X_test = df_test[feature_names].values
    y_train = df_train.target
    y_test = df_test.target

    # è®­ç»ƒ
    regession = linear_model.LinearRegression()
    model = regession.fit(X_train, y_train)

    # é¢„æµ‹
    y_pred = model.predict(X_test)

    # æ¨¡å‹è¯„ä»·
    df_result = pd.DataFrame({'ts_code': df_test.ts_code,
                              'trade_date': df_test.trade_date,
                              'y': y_test,
                              'y_pred': y_pred})

    # IC
    ic = df_result[['y', 'y_pred']].corr().iloc[0, 1]
    logger.info("é¢„æµ‹å€¼å’Œæ ‡ç­¾çš„ç›¸å…³æ€§(IC): %.2f%%", ic * 100)

    # Rank IC
    df_result['y_rank'] = df_result.y.rank(ascending=False)  # å¹¶åˆ—çš„é»˜è®¤ä½¿ç”¨æ’åå‡å€¼
    df_result['y_pred_rank'] = df_result.y_pred.rank(ascending=False)
    rank_ic = df_result[['y_rank', 'y_pred_rank']].corr().iloc[0, 1]
    logger.info("é¢„æµ‹å€¼å’Œæ ‡ç­¾çš„æ’åç›¸å…³æ€§(Rank IC): %.2f%%", rank_ic * 100)

    # åˆ†å±‚å›æµ‹ï¼Œæ¯ä¸ªè¡Œä¸šå†…åˆ†5ç±»
    df_result['industry'] = df_test.industry
    df_result['y_rank_in_industry'] = df_result.groupby('industry').y_pred.rank(ascending=False)  # æ¯è¡Œä¸šå†…æ’åï¼ˆæŒ‰è¡Œä¸šåˆ†ç»„ï¼‰
    df_result['class_label_in_industry'] = pd.qcut(df_result.y_rank_in_industry, q=5, labels=[1, 2, 3, 4, 5],
                                                   duplicates='drop')
    print(df_result)
    print(df_result.groupby('class_label_in_industry').mean())


# python -m mlstock.ml.main
if __name__ == '__main__':
    utils.init_logger(simple=True)
    start_date = "20180101"
    end_date = "20220101"
    num = 20
    main(start_date, end_date, num)
